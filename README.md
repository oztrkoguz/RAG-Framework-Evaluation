## RAG-Framework-Evaluation

![workflow2](https://github.com/user-attachments/assets/c766cd45-2b55-41db-9929-a6c0d1fae8e7)

#### This project aims to compare different Retrieval-Augmented Generation (RAG) frameworks. Using the same document and model, we evaluate LlamaIndex, Autogen, Langchain, Swarm and Crewai frameworks in terms of speed, accuracy and performance. These evaluations will help determine which framework is more effective in certain scenarios.




|       | Prompt Template | Model | Embbeding Model | Vectore Store | 
|-------|-----------------|-------|-----------------|---------------|
| Fixed | Use the following context pieces to answer the question at the end.<br> If you don't know the answer, just say you don't know, don't try to make up an answer.<br> Give answers in great detail. |gpt-3.5-turbo|BAAI/bge-small-en-v1.5|Chroma|


